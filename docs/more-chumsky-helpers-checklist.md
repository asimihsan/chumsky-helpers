# Chumsky Helper Roadmap & Checklist

> A living checklist that tracks what is needed to graduate our ad-hoc notes in docs/more-chumsky-helpers.md into a production-ready, **crate-agnostic** set of Chumsky parsers.  The list is ordered by dependency, so completing an item unblocks those below it.

---

## Legend

- [ ]  = not started
- [~]  = in progress / PR open
- [x]  = finished & merged to main

> **Tip**: Each helper must ship with
>
> 1. //! module-level docs explaining why it exists & how to reuse it.
> 2. Unit tests (happy & edge cases).
> 3. Property-based tests (proptest) that stress invalid inputs & recovery.
> 4. A public builder (see §Configuration) to tweak language-specific knobs.

---

## Core Token Infrastructure

| Status | Task | Notes |
| ------ | ---- | ----- |
| [ ] | token::Token<'src> enum finalised | Shared by all helpers, includes Span integration. |
| [ ] | token::Keyword and token::Punct sub-enums | Generated via bon for compile-time safety. |
| [ ] | lexer::TriviaPolicy trait | Allow consumers to keep/discard whitespace, docs, etc. |

---

## Primitive Parsers (no external state)

| Status | Helper | Description |
| ------ | ------ | ----------- |
| [ ] | whitespace() | Returns Token::Whitespace or gets .ignored() via policy. |
| [ ] | comment() / doc_comment() | Block & line variants; doc comments preserved. |
| [ ] | shebang() | Optional first token, useful for scripts. |
| [ ] | identifier(cfg) | Unicode-aware; rejects keywords supplied by cfg. |
| [ ] | keyword(cfg) | Zero-alloc recognition via perfect-hash set generated by bon. |
| [ ] | punct(cfg) | Longest-match first, list again generated by bon. |
| [ ] | int_literal(radix) | Handles _ separators, returns raw text. |
| [ ] | float_literal() | Optional exponent, rejects underscored edge cases. |
| [ ] | char_escape() | Parses \n, \t, etc., returns char. |
| [ ] | unicode_escape() | Parses \u{…} → char. |

---

## Stateful String Helpers

| Status | Helper | Key requirements |
| ------ | ------ | ---------------- |
| [ ] | raw_string(cfg) | Hash-delimited, single-line & multi-line modes. |
| [ ] | cooked_string(cfg) | Supports escapes & interpolation hooks. |
| [ ] | interpolated_string(cfg) | Emits StrStart/Text/Expr/StrEnd tokens, tracks paren depth. |

---

## Higher-level Composition

| Status | Component | Description |
| ------ | --------- | ----------- |
| [ ] | lexer::LexerBuilder | Fluent bon builder to choose keyword set, punct list, newline policy, etc. |
| [ ] | Automatic semicolon insertion | Kotlin-style newline handling based on TriviaPolicy. |
| [ ] | Error recovery strategy | recover_with(skip_then_retry_until) wrappers around critical helpers. |

---

## Testing Matrix

- **Unit tests**: Each helper has examples under tests/unit/<helper>_tests.rs.
- **Property tests**: Under tests/prop/, generated inputs ensure:
  - No panic on arbitrary bytes.
  - Lexed–then–re-serialized text equals original for valid literals.
  - Recovery does not loop forever.
- **Golden files**: End-to-end lexer output for a representative Pkl corpus stored in tests/golden/*.

---

## Documentation

- [ ] Cargo doc coverage ≥ 90 % (measured by cargo-llvm-cov doc --open).
- [ ] README.md badges: docs.rs, Crates.io, CI, coverage.
- [ ] Tutorials: *"From zero to tokens in 5 mins"* and *"Opting-in to interpolation"*.

---

## Configuration via Bon Builder

rust
let lexer = LexerBuilder::new()
    .with_keywords(["module", "import", "import*", "read?", ...])
    .with_punct(["...", "..?", "**", "??", "->", "==", "+", "-", ...])
    .enable_interpolation(true)
    .newline_policy(NewlinePolicy::SemicolonLike)
    .build();

The builder itself is generated by the #[builder] macro from the **bon** crate, ensuring sensible defaults and compile-time validation.

---

## Release Checklist

- [ ] cargo deny check passes.
- [ ] cargo fmt --check & cargo clippy --all-targets --all-features -- -D warnings clean.
- [ ] SemVer-tagged GitHub release with change-log.

---

*Edit this file in every PR to keep the roadmap honest!*
